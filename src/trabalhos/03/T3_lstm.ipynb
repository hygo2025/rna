{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOE2WTDAkagT"
      },
      "source": [
        "# üß†ü§ñ Treinamento de Redes LSTM para Classifica√ß√£o\n",
        "\n",
        "- **Deadline**: 24/08/2025\n",
        "- **Entrega**: O trabalho deve ser entregue via sistema Testr.\n",
        "- **Pontua√ß√£o**: 50% da nota do T2 (+1 ponto extra).\n",
        "- O trabalho deve ser realizado individualmente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU05mfhsQB6Y"
      },
      "source": [
        "## Especifica√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdAdEyR69fd1"
      },
      "source": [
        "\n",
        "### Contexto\n",
        "\n",
        "O trabalho consiste em realizar o treinamento de redes LSTM usando a base de dados [BBC News Archive dispon√≠vel no kaggle](https://www.kaggle.com/datasets/hgultekin/bbcnewsarchive?select=bbc-news-data.csv). Esta base de dados cont√©m 2.225 textos publicados no site de not√≠cias da BBC news entre 2004-2005. Cada not√≠cia foi classificada como sendo de um dos seguintes assuntos: business (neg√≥cios), entertainment (entretenimento), politics (pol√≠tica), sport (esportes), tech (tecnologia).\n",
        "\n",
        "O objetivo do trabalho √© treinar uma rede neural capaz de identificar o tema de um texto. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implementa√ß√£o \n",
        "\n",
        "- Use o notebook de classifica√ß√£o de sentimentos como ponto de partida.\n",
        "- use a biblioteca `kagglehub` para fazer o download do dataset no colab.\n",
        "- Um dos modelos de *word embeddings* dispon√≠veis na biblioteca `gensim` deve ser utilizado para mapear palavras em vetores. \n",
        "- Use o tipo `nn.LSTM` dispon√≠vel no `pytorch` (n√£o √© necess√°rio implementar a camada LSTM do zero).\n",
        "- Os dados devem ser divididos em treino, valida√ß√£o e teste. Use o conjunto de valida√ß√£o para ajustar hiperpar√¢metros e para selecionar o modelo com melhor generaliza√ß√£o. Avalie o modelo resultante usando o conjunto de teste apenas ao final. \n",
        "- Voc√™ pode optar por cortar os textos em um tamanho m√°ximo (e.g., 100 palavras), como fizemos no notebook, para que os testes n√£o demorem muito.\n",
        "- Use o ambiente de `GPU` do colab para evitar que o treinamento demore excessivamente.\n",
        "- Durante o desenvolvimento, √© uma boa id√©ia usar um subconjunto (e.g., 10%) das not√≠cias para que os testes sejam mais r√°pidos. Quando tudo estiver correto, fa√ßa o treinamento com a base completa.\n",
        "- Deve ser plotado o gr√°fico mostrando a evolu√ß√£o da fun√ß√£o de perda nos conjuntos de treino e valida√ß√£o. \n",
        "- Devem ser mostradas as m√©tricas geradas pela fun√ß√£o `classification_report` da biblioteca scikit-learn e a matriz de confus√£o para o conjunto de teste. \n",
        "- Fa√ßa alguns testes qualitativos com textos escritos com voc√™ (n√£o use textos da base de dados).\n",
        "- Discuta brevemente os resultados quantitativos e qualitativos (1-2 par√°grafos, no m√°ximo).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccJn9-T_Ts6e"
      },
      "source": [
        "\n",
        "### Pontos Extras\n",
        "\n",
        "Receber√° um ponto extra, o aluno que:\n",
        "- Utilizar um LLM baseado em Transformer pr√©-treinado (e.g., [BERT](https://medium.com/@davidlfliang/intro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6)) para mapear as not√≠cias em *embeddings*.\n",
        "- Utilizar uma rede Multilayer Perceptron para classificar os *embeddings*. \n",
        "- Comparar a performance desta solu√ß√£o com a LSTM. \n",
        "\n",
        "‚ö†Ô∏è**IMPORTANTE**‚ö†Ô∏è\n",
        "- N√£o √© necess√°rio (nem recomend√°vel considerando o prazo) tentar realizar *fine-tuning* do LLM pr√©-treinado.\n",
        "- Estes modelos s√£o SUPER-ULTRA-MASTER-BLASTER lentos na CPU. Use o ambiente de GPU do colab para evitar ficar 20h esperando para transformar os textos em *embeddings*.\n",
        "- Salve os embeddings depois da gera√ß√£o para evitar ter que ger√°-los novamente. Quando necess√°rio, fa√ßa upload do arquivo novamente para o colab."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
